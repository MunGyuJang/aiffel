{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "199a6ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ed9b699",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "class cfg:\n",
    "    Q_TKN = \"<usr>\"\n",
    "    A_TKN = \"<sys>\"\n",
    "    BOS = '<s>'\n",
    "    EOS = '</s>'\n",
    "    MASK = '<unused0>'\n",
    "    PAD = '<pad>'\n",
    "    max_len = 256\n",
    "    max_turns = 8\n",
    "    epochs = 5\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    learning_rate = 1e-4\n",
    "\n",
    "from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n",
    "            bos_token=cfg.BOS, eos_token=cfg.EOS, unk_token='<unk>',\n",
    "            pad_token=cfg.PAD, mask_token=cfg.MASK)\n",
    "model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c406f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋\n",
    "# 전처리 후, 텀을 나눠놓은 상태의 데이터를 입력으로 받음\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "\n",
    "import copy\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    \"\"\"\n",
    "        입력 : 전처리 후 대화 분리까지 완료된 데이터\n",
    "            ex) [\"밥 먹었어?\", \"응 밥 먹었어\", \"뭐 먹었어?\", \"샌드위치 먹었어\"]\n",
    "        출력 : 패딩까지 완료된 input_ids, token_type_ids, labels\n",
    "    \"\"\"\n",
    "    def __init__(self, data, tokenizer, cfg):\n",
    "        self.data = data\n",
    "        self.Q_TKN = cfg.Q_TKN\n",
    "        self.A_TKN = cfg.A_TKN\n",
    "        self.BOS = cfg.BOS\n",
    "        self.EOS = cfg.EOS\n",
    "        self.MASK = cfg.MASK\n",
    "        self.PAD = cfg.PAD\n",
    "        self.max_len = cfg.max_len\n",
    "        self.max_turns = cfg.max_turns\n",
    "        \n",
    "        self.input_ids = []\n",
    "        self.token_type_ids = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for i in tqdm(range(len(self.data))):\n",
    "            hists = []\n",
    "            dials = self.data[i]\n",
    "            \n",
    "            for u, utter in enumerate(dials):\n",
    "                if u % 2 == 0:\n",
    "                    hists.append(self.Q_TKN + utter)  # Speaker 1: User\n",
    "                else:\n",
    "                    hists.append(self.A_TKN + utter)  # Speaker 2: System\n",
    "            \n",
    "            max_turn = max(len(hists), self.max_turns) # max_turns을 넘으면 post\n",
    "            if max_turn % 2 != 0: max_turn -= 1 # user 대화로 끝남 방지\n",
    "                \n",
    "            for f in range(max_turn, 1, -2):\n",
    "                contexts = hists[:f]\n",
    "                if sum([len(l) for l in contexts]) > self.max_len-2: continue # BOS와 EOS 토큰을 추가하기 위해 -2\n",
    "                contexts[0] = self.BOS + contexts[0]\n",
    "                contexts[-1] = contexts[-1] + self.EOS\n",
    "                contexts = [tokenizer.encode(ctx) for ctx in contexts]\n",
    "                \n",
    "                token_type_id = [[ctx[0]] * len(ctx) if c != 0 else [ctx[1]] * len(ctx) for c, ctx in enumerate(contexts)]\n",
    "                label = [[-100] * len(ctx) if c != len(ctx) else ctx for c, ctx in enumerate(contexts)]\n",
    "                \n",
    "                input_id = list(chain.from_iterable(contexts))\n",
    "                token_type_id = list(chain.from_iterable(token_type_id))\n",
    "                label = list(chain.from_iterable(label))\n",
    "                \n",
    "                assert len(input_id) == len(token_type_id) == len(label), \"There is something wrong in dialogue process.\"\n",
    "                \n",
    "                input_id, token_type_id, label = self.make_padding(input_id, token_type_id, label)\n",
    "                \n",
    "                self.input_ids.append(input_id)\n",
    "                self.token_type_ids.append(token_type_id)\n",
    "                self.labels.append(label)\n",
    "                \n",
    "                break\n",
    "    \n",
    "    def make_padding(self, input_id, token_type_id, label):\n",
    "        left = self.max_len - len(input_id)\n",
    "        \n",
    "        input_id += [tokenizer.pad_token_id] * left\n",
    "        token_type_id += [tokenizer.pad_token_id] * left\n",
    "        label += [-100] * left\n",
    "        \n",
    "        return input_id, token_type_id, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.token_type_ids[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9733973a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;user&gt;우리 기간 언제까지나고 물어볼 수 없어 재등록 할 줄 알면 어케?&lt;bot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;user&gt;아침&lt;bot&gt;헉&lt;user&gt;잘안먹구&lt;bot&gt;일찍 인나짜나&lt;user&gt;좀잇으면...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;user&gt;18년도 잘한 일임니다&lt;bot&gt;넘나 레전급여행 개고생이었지만 뿌듯하네욘&lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;user&gt;나왔당 ㅋ 내일은 폭풍야근 예상이지만ㅋㅋㅋ&lt;bot&gt;잉? 늦느줄알고 암것도...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;user&gt;어디 괜차는사람업나 갑분이가&lt;bot&gt;훔 니 ?&lt;user&gt;그래 니가남자가 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>&lt;user&gt;커플템은 그냥 케이스 같은거 일러스트로 된거 구런걸로 할까해..&lt;bot&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>&lt;user&gt;졸려ㅠㅠ&lt;bot&gt;사주현도 졸리다&lt;user&gt;바로 잘 수 있지!! 사주현는 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>&lt;user&gt;뭔가 어제부터 오늘아침까지 빈속테 매운거넉어서그렁가 배가 계속아파&lt;bot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>&lt;user&gt;지갑 찾았어요??&lt;bot&gt;옹옹. 차에있더라구&lt;user&gt;거봐 내가 차에 있...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>&lt;user&gt;내일 꽃 보구????&lt;bot&gt;웅 밤새구 꽃보고 낮잠자고 먹고 낮잠자고 ㅎ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          conversation\n",
       "0    <user>우리 기간 언제까지나고 물어볼 수 없어 재등록 할 줄 알면 어케?<bot...\n",
       "1    <user>아침<bot>헉<user>잘안먹구<bot>일찍 인나짜나<user>좀잇으면...\n",
       "2    <user>18년도 잘한 일임니다<bot>넘나 레전급여행 개고생이었지만 뿌듯하네욘<...\n",
       "3    <user>나왔당 ㅋ 내일은 폭풍야근 예상이지만ㅋㅋㅋ<bot>잉? 늦느줄알고 암것도...\n",
       "4    <user>어디 괜차는사람업나 갑분이가<bot>훔 니 ?<user>그래 니가남자가 ...\n",
       "..                                                 ...\n",
       "995  <user>커플템은 그냥 케이스 같은거 일러스트로 된거 구런걸로 할까해..<bot>...\n",
       "996  <user>졸려ㅠㅠ<bot>사주현도 졸리다<user>바로 잘 수 있지!! 사주현는 ...\n",
       "997  <user>뭔가 어제부터 오늘아침까지 빈속테 매운거넉어서그렁가 배가 계속아파<bot...\n",
       "998  <user>지갑 찾았어요??<bot>옹옹. 차에있더라구<user>거봐 내가 차에 있...\n",
       "999  <user>내일 꽃 보구????<bot>웅 밤새구 꽃보고 낮잠자고 먹고 낮잠자고 ㅎ...\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Chatbot_Data = pd.read_csv('./data/multi_turn_tokens.csv')\n",
    "# Test 용으로 300개 데이터만 처리한다.\n",
    "Chatbot_Data = Chatbot_Data[:1000]\n",
    "Chatbot_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31f65456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<user>우리 기간 언제까지나고 물어볼 수 없어 재등록 할 줄 알면 어케?<bot>헉.. 어떻게말해야되지?<user>그냥 자연스레.. 안나오면되비 아저씨가 먼저 말하려나? 연장할거냐고..하면 뭐랗9?<bot>고민해볼게요..? 생각해보고나올게요..? 대본짜줘..<user>다음 달은 바빠서 어려울 것 같고 다음번에 다시 올게요 어떠니??<bot>오 역시말을잘하네 너가말해!<user>참내 너 방은철같아<bot>부끄러워..<user>\n",
      "\n",
      "['우리 기간 언제까지나고 물어볼 수 없어 재등록 할 줄 알면 어케?', '헉.. 어떻게말해야되지?', '그냥 자연스레.. 안나오면되비 아저씨가 먼저 말하려나? 연장할거냐고..하면 뭐랗9?', '고민해볼게요..? 생각해보고나올게요..? 대본짜줘..', '다음 달은 바빠서 어려울 것 같고 다음번에 다시 올게요 어떠니??', '오 역시말을잘하네 너가말해!', '참내 너 방은철같아', '부끄러워..']\n"
     ]
    }
   ],
   "source": [
    "def token_split(sentence):\n",
    "    sentence = re.sub(r\"<user>\", f\" {cfg.Q_TKN} \", sentence)\n",
    "    sentence = re.sub(r\"<bot>\", f\" {cfg.A_TKN} \", sentence)\n",
    "    sentence = sentence.split()\n",
    "    ids = [i for i, word in enumerate(sentence) if word == cfg.Q_TKN or word == cfg.A_TKN]\n",
    "    dials = [' '.join(sentence[ids[i]+1:ids[i+1]]) for i in range(len(ids)-1)] # ids[i]+1 : 토큰 포함, ids[i] : 토큰 미포함\n",
    "    dials = [i for i in dials if i.strip() != \"\"]\n",
    "    \n",
    "    return dials\n",
    "\n",
    "print(Chatbot_Data['conversation'][0])\n",
    "print()\n",
    "print(token_split(Chatbot_Data['conversation'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c744c526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[우리 기간 언제까지나고 물어볼 수 없어 재등록 할 줄 알면 어케?, 헉.. 어떻게...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[아침, 헉, 잘안먹구, 일찍 인나짜나, 좀잇으면 점심타임, 허어억 그럼 아점 땡겨야대]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[18년도 잘한 일임니다, 넘나 레전급여행 개고생이었지만 뿌듯하네욘, 저염, 가을 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[나왔당 ㅋ 내일은 폭풍야근 예상이지만ㅋㅋㅋ, 잉? 늦느줄알고 암것도안했는데 애들도...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[어디 괜차는사람업나 갑분이가, 훔 니 ?, 그래 니가남자가 어딧노 내가한재현씨잇을...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>[커플템은 그냥 케이스 같은거 일러스트로 된거 구런걸로 할까해.., 오오 귀엽다잉!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>[졸려ㅠㅠ, 사주현도 졸리다, 바로 잘 수 있지!! 사주현는 못자지!!!!!!! 졸...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>[뭔가 어제부터 오늘아침까지 빈속테 매운거넉어서그렁가 배가 계속아파, ㅠㅠ아안돼ㅠㅠ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>[지갑 찾았어요??, 옹옹. 차에있더라구, 거봐 내가 차에 있을거랬지 오빠의 행동반...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>[내일 꽃 보구????, 웅 밤새구 꽃보고 낮잠자고 먹고 낮잠자고 ㅎㅎ, 헉 밤 새...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          conversation\n",
       "0    [우리 기간 언제까지나고 물어볼 수 없어 재등록 할 줄 알면 어케?, 헉.. 어떻게...\n",
       "1    [아침, 헉, 잘안먹구, 일찍 인나짜나, 좀잇으면 점심타임, 허어억 그럼 아점 땡겨야대]\n",
       "2    [18년도 잘한 일임니다, 넘나 레전급여행 개고생이었지만 뿌듯하네욘, 저염, 가을 ...\n",
       "3    [나왔당 ㅋ 내일은 폭풍야근 예상이지만ㅋㅋㅋ, 잉? 늦느줄알고 암것도안했는데 애들도...\n",
       "4    [어디 괜차는사람업나 갑분이가, 훔 니 ?, 그래 니가남자가 어딧노 내가한재현씨잇을...\n",
       "..                                                 ...\n",
       "995  [커플템은 그냥 케이스 같은거 일러스트로 된거 구런걸로 할까해.., 오오 귀엽다잉!...\n",
       "996  [졸려ㅠㅠ, 사주현도 졸리다, 바로 잘 수 있지!! 사주현는 못자지!!!!!!! 졸...\n",
       "997  [뭔가 어제부터 오늘아침까지 빈속테 매운거넉어서그렁가 배가 계속아파, ㅠㅠ아안돼ㅠㅠ...\n",
       "998  [지갑 찾았어요??, 옹옹. 차에있더라구, 거봐 내가 차에 있을거랬지 오빠의 행동반...\n",
       "999  [내일 꽃 보구????, 웅 밤새구 꽃보고 낮잠자고 먹고 낮잠자고 ㅎㅎ, 헉 밤 새...\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Chatbot_Data['conversation'] = Chatbot_Data['conversation'].apply(token_split)\n",
    "\n",
    "Chatbot_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "827c763b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1289.92it/s]\n"
     ]
    }
   ],
   "source": [
    "def collate_batch(batch):\n",
    "    data = [item[0] for item in batch]\n",
    "    mask = [item[1] for item in batch]\n",
    "    label = [item[2] for item in batch]\n",
    "    return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n",
    "\n",
    "#윈도우 환경에서 num_workers 는 무조건 0으로 지정, 리눅스에서는 2\n",
    "train_set = CustomDataset(Chatbot_Data['conversation'], tokenizer, cfg)\n",
    "train_dataloader = DataLoader(train_set, batch_size=8, num_workers=2, shuffle=True, collate_fn=collate_batch,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f281826f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "token_ids ====>  tensor([[    0,     2, 39201,  ...,     3,     3,     3],\n",
      "        [    0,     2,  9235,  ...,     3,     3,     3],\n",
      "        [    0,     2,  9063,  ...,     3,     3,     3],\n",
      "        ...,\n",
      "        [    0,     2, 18767,  ...,     3,     3,     3],\n",
      "        [    0,     2, 10070,  ...,     3,     3,     3],\n",
      "        [    0,     2, 10099,  ...,     3,     3,     3]])\n",
      "mask =====>  tensor([[2, 2, 2,  ..., 3, 3, 3],\n",
      "        [2, 2, 2,  ..., 3, 3, 3],\n",
      "        [2, 2, 2,  ..., 3, 3, 3],\n",
      "        ...,\n",
      "        [2, 2, 2,  ..., 3, 3, 3],\n",
      "        [2, 2, 2,  ..., 3, 3, 3],\n",
      "        [2, 2, 2,  ..., 3, 3, 3]])\n",
      "label =====>  tensor([[-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        ...,\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100]])\n",
      "token_ids ====>  tensor([[    0,     2,  9252,  ...,     3,     3,     3],\n",
      "        [    0,     2, 15247,  ...,     3,     3,     3],\n",
      "        [    0,     2, 13811,  ...,     3,     3,     3],\n",
      "        ...,\n",
      "        [    0,     2,  9160,  ...,     3,     3,     3],\n",
      "        [    0,     2,  9502,  ...,     3,     3,     3],\n",
      "        [    0,     2, 28737,  ...,     3,     3,     3]])\n",
      "mask =====>  tensor([[2, 2, 2,  ..., 3, 3, 3],\n",
      "        [2, 2, 2,  ..., 3, 3, 3],\n",
      "        [2, 2, 2,  ..., 3, 3, 3],\n",
      "        ...,\n",
      "        [2, 2, 2,  ..., 3, 3, 3],\n",
      "        [2, 2, 2,  ..., 3, 3, 3],\n",
      "        [2, 2, 2,  ..., 3, 3, 3]])\n",
      "label =====>  tensor([[-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        ...,\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100]])\n",
      "token_ids ====>  tensor([[    0,     2,  9063,  ...,     3,     3,     3],\n",
      "        [    0,     2,  9572,  ...,     3,     3,     3],\n",
      "        [    0,     2, 10138,  ...,     3,     3,     3],\n",
      "        ...,\n",
      "        [    0,     2,  9063,  ...,     3,     3,     3],\n",
      "        [    0,     2,  9893,  ...,     3,     3,     3],\n",
      "        [    0,     2, 11967,  ...,     3,     3,     3]])\n",
      "mask =====>  tensor([[2, 2, 2,  ..., 3, 3, 3],\n",
      "        [2, 2, 2,  ..., 3, 3, 3],\n",
      "        [2, 2, 2,  ..., 3, 3, 3],\n",
      "        ...,\n",
      "        [2, 2, 2,  ..., 3, 3, 3],\n",
      "        [2, 2, 2,  ..., 3, 3, 3],\n",
      "        [2, 2, 2,  ..., 3, 3, 3]])\n",
      "label =====>  tensor([[-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        ...,\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100]])\n",
      "token_ids ====>  tensor([[    0,     2,  9214,  ...,     3,     3,     3],\n",
      "        [    0,     2,  9040,  ...,     3,     3,     3],\n",
      "        [    0,     2, 12102,  ...,     3,     3,     3],\n",
      "        ...,\n",
      "        [    0,     2,  9252,  ...,     3,     3,     3],\n",
      "        [    0,     2,  9893,  ...,     3,     3,     3],\n",
      "        [    0,     2, 22301,  ...,     3,     3,     3]])\n",
      "mask =====>  tensor([[2, 2, 2,  ..., 3, 3, 3],\n",
      "        [2, 2, 2,  ..., 3, 3, 3],\n",
      "        [2, 2, 2,  ..., 3, 3, 3],\n",
      "        ...,\n",
      "        [2, 2, 2,  ..., 3, 3, 3],\n",
      "        [2, 2, 2,  ..., 3, 3, 3],\n",
      "        [2, 2, 2,  ..., 3, 3, 3]])\n",
      "label =====>  tensor([[-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        ...,\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100]])\n",
      "token_ids ====>  tensor([[    0,     2,  9741,  ...,     3,     3,     3],\n",
      "        [    0,     2,  9234,  ...,     3,     3,     3],\n",
      "        [    0,     2, 31187,  ...,     3,     3,     3],\n",
      "        ...,\n",
      "        [    0,     2,  9407,  ...,     3,     3,     3],\n",
      "        [    0,     2,  9769,  ...,     3,     3,     3],\n",
      "        [    0,     2, 40734,  ...,     3,     3,     3]])\n",
      "mask =====>  tensor([[2, 2, 2,  ..., 3, 3, 3],\n",
      "        [2, 2, 2,  ..., 3, 3, 3],\n",
      "        [2, 2, 2,  ..., 3, 3, 3],\n",
      "        ...,\n",
      "        [2, 2, 2,  ..., 3, 3, 3],\n",
      "        [2, 2, 2,  ..., 3, 3, 3],\n",
      "        [2, 2, 2,  ..., 3, 3, 3]])\n",
      "label =====>  tensor([[-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        ...,\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100]])\n",
      "token_ids ====>  tensor([[    0,     2, 22031,  ...,     3,     3,     3],\n",
      "        [    0,     2, 31658,  ...,     3,     3,     3],\n",
      "        [    0,     2, 46651,  ...,     3,     3,     3],\n",
      "        ...,\n",
      "        [    0,     2,  9050,  ...,     3,     3,     3],\n",
      "        [    0,     2, 12857,  ...,     3,     3,     3],\n",
      "        [    0,     2,  9774,  ...,     3,     3,     3]])\n",
      "mask =====>  tensor([[2, 2, 2,  ..., 3, 3, 3],\n",
      "        [2, 2, 2,  ..., 3, 3, 3],\n",
      "        [2, 2, 2,  ..., 3, 3, 3],\n",
      "        ...,\n",
      "        [2, 2, 2,  ..., 3, 3, 3],\n",
      "        [2, 2, 2,  ..., 3, 3, 3],\n",
      "        [2, 2, 2,  ..., 3, 3, 3]])\n",
      "label =====>  tensor([[-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        ...,\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100]])\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "print(\"start\")\n",
    "for batch_idx, samples in enumerate(train_dataloader):\n",
    "    if batch_idx > 5:\n",
    "        break\n",
    "    token_ids, mask, label = samples\n",
    "    print(\"token_ids ====> \", token_ids)\n",
    "    print(\"mask =====> \", mask)\n",
    "    print(\"label =====> \", label)\n",
    "print(\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7faf9986",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatBot:\n",
    "    losses = []\n",
    "    \n",
    "    def __init__(self, model, dataloader, tokenizer, cfg):\n",
    "        \"\"\"\n",
    "            Args : model, dataloader, tokenizer, cfg\n",
    "        \"\"\"\n",
    "        ChatBot.model = model\n",
    "        ChatBot.dataloader = dataloader\n",
    "        ChatBot.tokenizer = tokenizer\n",
    "        ChatBot.device = cfg.device\n",
    "        ChatBot.optim = torch.optim.Adam(model.parameters(), lr=cfg.learning_rate)\n",
    "        \n",
    "        ChatBot.user_token_id = tokenizer.get_vocab()[cfg.Q_TKN]\n",
    "        ChatBot.bot_token_id = tokenizer.get_vocab()[cfg.A_TKN]\n",
    "        ChatBot.max_len = cfg.max_len\n",
    "        ChatBot.max_turns = cfg.max_turns\n",
    "    \n",
    "    @classmethod\n",
    "    def train(cls, epochs, save=None):\n",
    "        \"\"\"\n",
    "            save : 모델을 저장할 경로\n",
    "        \"\"\"\n",
    "        cls.model.to(cls.device)\n",
    "        for epoch in range(epochs):\n",
    "            cls.model.train()\n",
    "            print(f\"\\n Epoch {epoch+1}/{epochs}\", sep=\"\\n\")\n",
    "            starttime = time.time()\n",
    "            batch_loss = []\n",
    "\n",
    "            for i, batch in enumerate(cls.dataloader):\n",
    "                input_ids, token_type_ids, labels = batch\n",
    "                input_ids, token_type_ids, labels = \\\n",
    "                    input_ids.to(cls.device), token_type_ids.to(cls.device), labels.to(cls.device)\n",
    "                \n",
    "                outputs = cls.model(\n",
    "                    input_ids=input_ids,\n",
    "                    token_type_ids = token_type_ids,\n",
    "                    labels = labels\n",
    "                )\n",
    "                \n",
    "                loss, logits = outputs[0], outputs[1]\n",
    "                \n",
    "                cls.optim.zero_grad()\n",
    "                loss.backward()\n",
    "                cls.optim.step()\n",
    "\n",
    "                batch_loss.append(loss.item())\n",
    "                \n",
    "                print(cls.status(cls, i+1, time.time()-starttime, np.mean(batch_loss)), end='\\r')\n",
    "\n",
    "            cls.losses.append(np.mean(batch_loss))\n",
    "            \n",
    "            if save:\n",
    "                PATH = f'{save}_epochs-{epoch+1}_loss-{np.mean(batch_loss)}.pth'\n",
    "                torch.save(model.state_dict(), PATH)\n",
    "    \n",
    "    def status(self, step, time, loss):\n",
    "        return \"step : %d/%d - %ds | loss : %.6f | %.2fit/s\"%(\n",
    "            step,\n",
    "            len(self.dataloader),\n",
    "            int(time),\n",
    "            loss,\n",
    "            step/time\n",
    "        )\n",
    "    \n",
    "    @classmethod\n",
    "    def load_model(cls, PATH):\n",
    "        \"\"\"\n",
    "            PATH : pth 파일이 저장된 경로\n",
    "        \"\"\"\n",
    "        cls.model.load_state_dict(torch.load(PATH))\n",
    "        print(\"model loaded.\")\n",
    "    \n",
    "    @classmethod\n",
    "    def talk(cls):\n",
    "        print(\"Escape ment : quit\")\n",
    "        with torch.no_grad():\n",
    "            cur_speaker = 1\n",
    "            input_ids_list = []\n",
    "            token_type_ids_list = []\n",
    "            t = 0\n",
    "            output_id = None\n",
    "\n",
    "            while True:\n",
    "                if cur_speaker == 1:\n",
    "                    cur_speaker_id = cls.user_token_id\n",
    "                    utter = input(\"You: \")\n",
    "\n",
    "                    if utter == \"quit\":\n",
    "                        print(\"Bot: Good bye.\")\n",
    "                        break\n",
    "\n",
    "                    input_id = [cur_speaker_id] + cls.tokenizer.encode(utter)\n",
    "\n",
    "                    if t == 0:\n",
    "                        input_id = [cls.tokenizer.bos_token_id] + input_id\n",
    "                else:\n",
    "                    cur_speaker_id = cls.bot_token_id\n",
    "                    input_id = copy.deepcopy(output_id)\n",
    "\n",
    "                token_type_id = [cur_speaker_id] * len(input_id)\n",
    "\n",
    "                if input_id[-1] == cls.tokenizer.eos_token_id:\n",
    "                    input_id = input_id[:-1]\n",
    "                    token_type_id = token_type_id[:-1] \n",
    "\n",
    "                input_ids_list.append(input_id)\n",
    "                token_type_ids_list.append(token_type_id)\n",
    "\n",
    "                if t >= cls.max_turns:\n",
    "                    input_ids_list = input_ids_list[1:]\n",
    "                    token_type_ids_list = token_type_ids_list[1:]\n",
    "\n",
    "                next_speaker = (cur_speaker % 2) + 1\n",
    "                if next_speaker == 1:\n",
    "                    next_speaker_id = cls.user_token_id\n",
    "                else:\n",
    "                    next_speaker_id = cls.bot_token_id\n",
    "\n",
    "                if cur_speaker == 1:\n",
    "                    output_id = cls.nucleus_sampling(cls, input_ids_list, token_type_ids_list, next_speaker_id)\n",
    "                    res = cls.tokenizer.decode(output_id)\n",
    "\n",
    "                    print(f\"Bot: {res}\")\n",
    "\n",
    "                cur_speaker = copy.deepcopy(next_speaker)\n",
    "                t += 1\n",
    "\n",
    "    def nucleus_sampling(self, input_ids_list, token_type_ids_list, next_speaker_id):\n",
    "        output_id = []\n",
    "        res_id = [next_speaker_id]\n",
    "        res_type_id = [next_speaker_id]\n",
    "        for pos in range(self.max_len):\n",
    "            input_ids = list(chain.from_iterable(input_ids_list)) + res_id\n",
    "            token_type_ids = list(chain.from_iterable(token_type_ids_list)) + res_type_id\n",
    "            input_len = len(input_ids)\n",
    "\n",
    "            left = self.max_len - len(input_ids)\n",
    "            input_ids += [self.tokenizer.pad_token_id] * left\n",
    "            token_type_ids += [self.tokenizer.pad_token_id] * left\n",
    "\n",
    "            assert len(input_ids) == len(token_type_ids), \"There is something wrong in dialogue process.\"\n",
    "\n",
    "            input_ids = torch.LongTensor(input_ids).unsqueeze(0).to(self.device)  # (1, L)\n",
    "            token_type_ids = torch.LongTensor(token_type_ids).unsqueeze(0).to(self.device)  # (1, L)\n",
    "\n",
    "            output = self.model(input_ids=input_ids, token_type_ids=token_type_ids)[0][:, input_len-1]  # (1, vocab_size)\n",
    "            output = F.softmax(output, dim=-1)  # (1, vocab_size)\n",
    "\n",
    "            sorted_probs, sorted_idxs = torch.sort(output, descending=True)\n",
    "            cumsum_probs = torch.cumsum(sorted_probs, dim=-1)  # (1, vocab_size)\n",
    "            idx_remove = cumsum_probs > 0.9\n",
    "            sorted_probs[idx_remove] = 1e-8\n",
    "            sorted_probs /= torch.sum(sorted_probs, dim=-1, keepdim=True)  # (1, vocab_size)\n",
    "\n",
    "            # Random sampling\n",
    "            probs = torch.zeros(output.shape).to(self.device).scatter_(-1, sorted_idxs, sorted_probs)  # (1, vocab_size)\n",
    "            idx = torch.multinomial(probs, 1).squeeze(-1).squeeze(0).item()\n",
    "\n",
    "            if len(output_id) == self.max_len or idx == self.tokenizer.eos_token_id:\n",
    "                break\n",
    "            else:\n",
    "                output_id.append(idx)\n",
    "                res_id.append(idx)\n",
    "                res_type_id.append(next_speaker_id)\n",
    "\n",
    "        return output_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ce2f5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prototype = ChatBot(model, train_dataloader, tokenizer, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53498acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1/5\n",
      "step : 125/125 - 65s | loss : 4.769154 | 1.91it/s\n",
      " Epoch 2/5\n",
      "step : 125/125 - 64s | loss : 3.240867 | 1.93it/s\n",
      " Epoch 3/5\n",
      "step : 125/125 - 65s | loss : 2.617334 | 1.92it/s\n",
      " Epoch 4/5\n",
      "step : 125/125 - 65s | loss : 2.102897 | 1.92it/s\n",
      " Epoch 5/5\n",
      "step : 125/125 - 64s | loss : 2.115264 | 1.92it/s\r"
     ]
    }
   ],
   "source": [
    "prototype.train(cfg.epochs, save='./skt-kogpt2_1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96c837db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escape ment : quit\n",
      "You: 카페갈래?\n",
      "Bot: ㅠㅠᄏᄏᄏᄏᄏᄏᄏᄏ丑<usr> 웅<usr> 음제<usr> 바로 떠올랏네<usr> 두세 유전자가 없지..<usr> ᄏ 나간다.\n",
      " 서울대인가..<usr>ᄏ 식품가 저..<usr> 돌아돌아<unk> 정부도시 이미지인데..ᄏ 들어가는.<usr> 맞아..ᄏ 자격을 좋지....ᄏ 200년 바로 떠올..ᄏᄏ개인. 교육이라栻  1종 아직 수치인데..ᄏ 데려..<sys> 기준 지금..ᄏᄏ첨의..\n",
      "You: 싫으면 말고\n",
      "Bot: 뭐 뭐 그렇..\n",
      "You: quit\n",
      "Bot: Good bye.\n"
     ]
    }
   ],
   "source": [
    "prototype.talk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21df1924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(prototype.losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a0e0e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path = './chatbot_multi-turn_340000_6.pth'\n",
    "prototype.load_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "341b13ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escape ment : quit\n",
      "You: 카페갈래?\n",
      "Bot: 결제했다\n",
      "You: 뭐 샀는데?\n",
      "Bot: 제넥합\n",
      "You: 뭐야 그건 처음 들어봐\n",
      "Bot: 아직 품레인다 가지고 나와있길 휴양ᄒ\n",
      "You: 뭐라는거야 자꾸\n",
      "Bot: 하루에욜저녁대여\n",
      "You: 그래 알았어 좀만 더 학습하자\n",
      "Bot: 엉 너무 추워요\n",
      "You: quit\n",
      "Bot: Good bye.\n"
     ]
    }
   ],
   "source": [
    "prototype.talk()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
